{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from omegaconf import OmegaConf\n",
    "import albumentations as A\n",
    "\n",
    "from src.utils import instantiate_from_config, get_obj_from_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common:\n",
      "  gpus:\n",
      "  - 0\n",
      "  seed: 17\n",
      "  folds_count: null\n",
      "  batch_size: 2\n",
      "  num_workers: 2\n",
      "  epochs: 256\n",
      "  exp_name: test_experiment\n",
      "  wandb: false\n",
      "model:\n",
      "  target: segmentation_models_pytorch.Unet\n",
      "  params:\n",
      "    encoder_name: resnet34\n",
      "    classes: 4\n",
      "criterions:\n",
      "- target: segmentation_models_pytorch.losses.FocalLoss\n",
      "  params:\n",
      "    mode: multiclass\n",
      "  weight: 0.5\n",
      "  name: focal\n",
      "- target: segmentation_models_pytorch.losses.JaccardLoss\n",
      "  params:\n",
      "    mode: multiclass\n",
      "  weight: 0.5\n",
      "  name: jaccard\n",
      "optimizers:\n",
      "- target: torch.optim.Adam\n",
      "  params:\n",
      "    lr: 0.002\n",
      "  scheduler:\n",
      "    target: pl_bolts.optimizers.lr_scheduler.LinearWarmupCosineAnnealingLR\n",
      "    params:\n",
      "      warmup_epochs: 16\n",
      "      max_epochs: 256\n",
      "      warmup_start_lr: 0.001\n",
      "    additional:\n",
      "      monitor: iou_valid\n",
      "metrics:\n",
      "- target: segmentation_models_pytorch.utils.metrics.IoU\n",
      "  params:\n",
      "    threshold: 0.5\n",
      "  name: iou\n",
      "  use_bg: false\n",
      "callbacks:\n",
      "- target: pytorch_lightning.callbacks.LearningRateMonitor\n",
      "- target: pytorch_lightning.callbacks.ModelCheckpoint\n",
      "  params:\n",
      "    dirpath: ./models\n",
      "    filename: best-{epoch:02d}-{iou_valid:2.2f}\n",
      "    monitor: iou_valid\n",
      "    mode: max\n",
      "    save_top_k: 1\n",
      "    save_last: true\n",
      "datasets:\n",
      "  train:\n",
      "    target: datasets.TrainDataset\n",
      "    params:\n",
      "      img_h: 256\n",
      "      img_w: 256\n",
      "      labels:\n",
      "      - 0\n",
      "      - 6\n",
      "      - 7\n",
      "      - 10\n",
      "      images_dir: /home/user/datasets/denu/images\n",
      "      masks_dir: /home/user/datasets/denu/mask\n",
      "  valid:\n",
      "    target: datasets.TrainDataset\n",
      "    params:\n",
      "      img_h: 256\n",
      "      img_w: 256\n",
      "      labels:\n",
      "      - 0\n",
      "      - 6\n",
      "      - 7\n",
      "      - 10\n",
      "      images_dir: /home/user/datasets/denu/images\n",
      "      masks_dir: /home/user/datasets/denu/mask\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = OmegaConf.load('./configs/base_config.yaml', )\n",
    "print(OmegaConf.to_yaml(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(config['common']['seed'], workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN_IMAGES_FOLDER = '/home/user/datasets/hubmap-organ-segmentation/train_images'\n",
    "# TRAIN_MASKS_FOLDER = '/home/user/datasets/hubmap-organ-segmentation/train_masks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, images_dir, masks_dir, labels, img_w=256, img_h=256, augs=None, img_format='png'):\n",
    "        self.img_names = get_img_names(images_dir, img_format=img_format)\n",
    "        self.images_dir = images_dir\n",
    "        self.masks_dir = masks_dir\n",
    "        self.labels = labels\n",
    "        self.img_w = img_w\n",
    "        self.img_h = img_h\n",
    "        self.augs = augs\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name = self.img_names[index]\n",
    "        img_path = os.path.join(self.images_dir, img_name)\n",
    "        msk_path = os.path.join(self.masks_dir, img_name)\n",
    "\n",
    "        image = cv2.imread(img_path)\n",
    "        mask = cv2.imread(msk_path, 0)\n",
    "\n",
    "        if self.augs is not None:\n",
    "            item = self.augs(image=image, mask=mask)\n",
    "            image = item['image']\n",
    "            mask = item['mask']\n",
    "\n",
    "        image = preprocess_image(image, img_w=self.img_w, img_h=self.img_h)\n",
    "        oh_mask = preprocess_mask2onehot(mask, self.labels, img_w=self.img_w, img_h=self.img_h)\n",
    "        sg_mask = preprocess_single_mask(mask, self.labels, img_w=self.img_w, img_h=self.img_h)\n",
    "\n",
    "        return {\n",
    "            'image': image, \n",
    "            'oh_mask': oh_mask, \n",
    "            'sg_mask': sg_mask,\n",
    "        }\n",
    "\n",
    "def get_train_augs():\n",
    "    return A.Compose([\n",
    "            A.RandomCrop(512*1, 512*1, p=1),\n",
    "            A.ToGray(p=0.15),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.15),\n",
    "            A.Rotate(limit=180, border_mode=3, p=0.5),\n",
    "            A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "            A.RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "        ], p=1.0)\n",
    "\n",
    "\n",
    "def get_valid_augs():\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningModel(pl.LightningModule):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.model = instantiate_from_config(config['model'])\n",
    "        \n",
    "        self.criterions = {x['name']: instantiate_from_config(x) for x in config['criterions']}\n",
    "        self.crit_weights = {x['name']: x['weight'] for x in config['criterions']}\n",
    "        \n",
    "        self.metrics = {x['name']: instantiate_from_config(x) for x in config['metrics']}\n",
    "        self.use_bg = {x['name']: x['use_bg'] for x in config['metrics']}\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def _common_step(self, batch, batch_idx, stage):\n",
    "        gt_img, sg_mask, oh_mask = batch['image'], batch['sg_mask'].long(), batch['oh_mask']\n",
    "        pr_msk = self.model(gt_img)\n",
    "         \n",
    "        loss = 0\n",
    "        for c_name in self.criterions.keys():\n",
    "            c_loss = self.criterions[c_name](pr_msk, sg_mask) * self.crit_weights[c_name]\n",
    "            self.log(f\"{c_name}_loss_{stage}\", c_loss, on_epoch=True, prog_bar=True)\n",
    "            loss += c_loss\n",
    "        self.log(f\"total_loss_{stage}\", loss, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        for m_name in self.metrics.keys():\n",
    "            metric_info = f\"{m_name}_{stage}\"\n",
    "            index = 0 if self.use_bg[m_name] else 1\n",
    "            metric_value = self.metrics[m_name](pr_msk[:, index:, :, :], oh_mask[:, index:, :, :])\n",
    "            self.log(metric_info, metric_value, on_epoch=True, prog_bar=True)              \n",
    "        return {\n",
    "            'loss': loss,\n",
    "        }\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        item = self._common_step(batch, batch_idx, 'train')\n",
    "        return item\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        item = self._common_step(batch, batch_idx, 'valid')\n",
    "        return item\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        item = self._common_step(batch, batch_idx, 'test')\n",
    "        return item\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizers = []\n",
    "        schedulers = []\n",
    "        \n",
    "        for item in self.config['optimizers']:\n",
    "            optimizer = get_obj_from_str(item['target'])(\n",
    "                self.parameters(), \n",
    "                **item.get('params', {}))\n",
    "            optimizers.append(optimizer)\n",
    "            \n",
    "            scheduler = get_obj_from_str(item['scheduler']['target'])(\n",
    "                optimizer = optimizer, \n",
    "                **item['scheduler'].get('params', {}))\n",
    "            schedulers.append({\n",
    "                'scheduler':scheduler,\n",
    "                **item['scheduler']['additional'],\n",
    "            })\n",
    "        \n",
    "        return optimizers, schedulers\n",
    "    \n",
    "    def configure_callbacks(self):\n",
    "        callbacks = []\n",
    "        for item in self.config.get('callbacks', []):\n",
    "            callback = instantiate_from_config(item)\n",
    "            callbacks.append(callback)  \n",
    "        return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.train = instantiate_from_config(config['datasets']['train'])\n",
    "        self.train.augs = get_train_augs()\n",
    "\n",
    "        self.valid = instantiate_from_config(config['datasets']['valid'])\n",
    "        self.valid.augs = get_valid_augs()\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train, \n",
    "                          batch_size=self.config['common'].get('batch_size', 1),  \n",
    "                          num_workers=self.config['common'].get('num_workers', 1),\n",
    "                          drop_last=self.config['common'].get('drop_last', True),\n",
    "                          pin_memory=self.config['common'].get('pin_memory', True),\n",
    "                          shuffle=self.config['common'].get('shuffle', True),)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.valid, \n",
    "                          batch_size=self.config['common'].get('batch_size', 1),  \n",
    "                          num_workers=self.config['common'].get('num_workers', 1),\n",
    "                          drop_last=self.config['common'].get('drop_last', False),\n",
    "                          pin_memory=self.config['common'].get('pin_memory', True),\n",
    "                          shuffle=self.config['common'].get('shuffle', False),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: ModelCheckpoint\n",
      "/home/user/Projects/segmentation_baseline/vevn/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:611: UserWarning: Checkpoint directory /home/user/Projects/segmentation_baseline/models exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | Unet | 24.4 M\n",
      "-------------------------------\n",
      "24.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "24.4 M    Total params\n",
      "97.747    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1930601d7e8472ba2c0bd18333d3e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Projects/segmentation_baseline/vevn/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/user/Projects/segmentation_baseline/vevn/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/user/Projects/segmentation_baseline/vevn/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1933: PossibleUserWarning: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fcc9782d2eb4c4abd33f0b0e57b303c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b62dab430dbf412a8916e8fee8deac96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb52802565484b8196416699a40a2e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Projects/segmentation_baseline/vevn/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:726: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "model = LightningModel(config)\n",
    "datamodule = DataModule(config)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=config['common']['epochs'], gpus=config['common']['gpus'])\n",
    "trainer.fit(model, datamodule) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segmentation_venv",
   "language": "python",
   "name": "segmentation_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
