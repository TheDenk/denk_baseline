# python run.py --config=./projects/aij_2023/config-custom-final-finetune.yaml

common:
  exp_name: custom-final-finetune-32-2-1001-medium-augs-dataset-18
  project_name: aij_2023
  save_dir: output
  seed: 17
  max_epochs: 48
  batch_size: 16 
  num_workers: 16 

loggers:
- target: pytorch_lightning.loggers.WandbLogger
- target: pytorch_lightning.loggers.TensorBoardLogger

lightning_model: denk_baseline.lightning_models.ClassificationMulticlassModel

trainer:
  target: pytorch_lightning.Trainer
  params:
    devices: [0]
    max_epochs: 128
    accelerator: gpu
    precision: bf16

model:
  target: projects.aij_2023.models.mvit.model.CustomMvitModel
  params:
    backbone: x2
    mvit_kwargs:
      num_classes: 1001
      backbone_channels: 64
      head_channels: 768
      ignore_layers: []
      arch: 
        embed_dims: 96
        num_layers: 12
        num_heads: 1
        downscale_indices: [1, 3, 11]
    ckpt_path: ./pretrain_weights/custom-mvit-full-x2-18.ckpt
    ignore_layers: 
    - mvit.backbone.blocks.11.attn.qkv.bias
    - mvit.backbone.blocks.11.attn.proj.weight
    - mvit.backbone.blocks.11.attn.proj.bias
    - mvit.backbone.blocks.11.norm2.weight
    - mvit.backbone.blocks.11.norm2.bias
    - mvit.backbone.blocks.11.mlp.fc1.weight
    - mvit.backbone.blocks.11.mlp.fc1.bias
    - mvit.backbone.blocks.11.mlp.fc2.weight
    - mvit.backbone.blocks.11.mlp.fc2.bias
    - mvit.backbone.blocks.11.attn.qkv.weight

criterions:
- target: torch.nn.CrossEntropyLoss
  params:
    label_smoothing: 0.1
  weight: 1.0
  name: ce

optimizers:
- target: torch.optim.AdamW
  params:
    lr: 0.0001
    weight_decay: 0.05
  scheduler:
    target: pl_bolts.optimizers.lr_scheduler.LinearWarmupCosineAnnealingLR
    params:
      warmup_epochs: 2
      max_epochs: 128
      warmup_start_lr: 0.00005
      eta_min: 0.00001
    additional:
      monitor: f1score_valid
    
metrics:
- target: torchmetrics.Precision
  name: precision
  params:
    num_classes: 1001
    task: multiclass
    average: macro
- target: torchmetrics.Recall
  name: recall
  params:
    num_classes: 1001
    task: multiclass
    average: macro
- target: torchmetrics.F1Score
  name: f1score
  params:
    num_classes: 1001
    task: multiclass
    average: macro
- target: denk_baseline.metrics.MeanAccuracyScore
  name: mascore

callbacks:
- target: pytorch_lightning.callbacks.LearningRateMonitor
- target: pytorch_lightning.callbacks.ModelCheckpoint
  params:
    filename: best_f1score-{epoch:03d}-{f1score_valid:3.3f}-{precision_valid:3.3f}-{recall_valid:3.3f}-{total_loss_valid:3.3f}
    monitor: f1score_valid
    mode: max
    save_top_k: 3
    save_last: false
    save_weights_only: false

datasets:
  train:
    target: projects.aij_2023.dataset.TrainVideoDataset
    params:
      csv_path: projects/aij_2023/data/train_15.csv
      json_path: projects/aij_2023/data/classes.json
      video_folder: /home/user/datasets/slovo/video
      min_side: 256
      sample_size: 224 
      sample_stride: 2 
      sample_n_frames: 32
      start_delta: 4
      augs_proba: medium
      use_dwt: false
  valid:
    target: projects.aij_2023.dataset.ValidVideoDataset
    params:
      csv_path: projects/aij_2023/data/test_15.csv
      json_path: projects/aij_2023/data/classes.json
      video_folder: /home/user/datasets/slovo/video
      min_side: 256
      sample_size: 224 
      sample_stride: 2 
      sample_n_frames: 32
      use_dwt: false

dataloaders:
  train:
    target: torch.utils.data.DataLoader
    params:
      shuffle: false
      batch_size: 32
      num_workers: 16
      drop_last: false
      pin_memory: true
    sampler: 
      target: torch.utils.data.RandomSampler
  valid:
    target: torch.utils.data.DataLoader
    params:
      shuffle: false
      batch_size: 32
      num_workers: 16
      drop_last: false
      pin_memory: true
    sampler: 
      target: torch.utils.data.SequentialSampler
