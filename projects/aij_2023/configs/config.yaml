# python run.py --config=./projects/aij_2023/config.yaml

common:
  exp_name: custom-full-dwt-mvit-x2-finetune-32-2-1001-medium-augs
  project_name: aij_2023
  save_dir: output
  seed: 17
  max_epochs: 32
  batch_size: 16 
  num_workers: 16 

loggers:
- target: pytorch_lightning.loggers.WandbLogger
- target: pytorch_lightning.loggers.TensorBoardLogger

# lightning_model: denk_baseline.lightning_models.ClassificationMulticlassDistillationModel
lightning_model: denk_baseline.lightning_models.ClassificationMulticlassModel

trainer:
  target: pytorch_lightning.Trainer
  params:
    devices: [0]
    max_epochs: 128
    accelerator: gpu
    precision: bf16

# model:
#   target: projects.aij_2023.models.swiftformer.SwiftFormer
#   params:
#     num_classes: 34
#     frame_count: 16
#     layers: [3, 3, 6, 4]
#     embed_dims: [48, 56, 112, 220]
#     downsamples: [True, True, True, True]
#     vit_num: 1
#     temporal_indices: [3, 4, 5, 6]
#     conv3d_indices: []

# model:
#   target: projects.aij_2023.models.mobilenetv3.MobileNetV3
#   params:
#     arch: mobilenet_v3_large
#     num_classes: 34
#     frame_count: 32
#     temporal_indices: [8, 10, 12, 14]
#     conv3d_indices: [11, 13]

# model:
#   target: projects.aij_2023.models.mobilenetv2.MobileNetV2
#   params:
#     sample_size: 224
#     num_classes: 1001
#     frame_count: 16
#     temporal_indices: []

model:
  target: projects.aij_2023.models.mvit.model.CustomMvitModel
  params:
    backbone: x0
    mvit_kwargs:
      num_classes: 1001
      ckpt_path: ./pretrain_weights/mvit32.2_small_state_dict.pt  
      backbone_channels: 3
      head_channels: 768
      ignore_layers: 
      - 'backbone.patch_embed.projection.weight'
      # - 'backbone.norm3.weight'
      # - 'backbone.norm3.bias'
      # - 'cls_head.fc_cls.weight'
      arch: 
        embed_dims: 96
        num_layers: 16
        num_heads: 1
        downscale_indices: [1, 3, 14]
  #   ckpt_path: ./pretrain_weights/custom-mvit-full-dwt-x1.ckpt
  #   ignore_layers: [mvit.backbone.patch_embed.projection.weight]

# model:
#   target: projects.aij_2023.models.mvit.model.MViTModel
#   params:
#     num_classes: 1001
#     ckpt_path: ./pretrain_weights/mvit32.2_small_state_dict.pt  
#     backbone_channels: 12
#     head_channels: 768
#     ignore_layers: 
      # - 'backbone.patch_embed.projection.weight'
      # - 'backbone.norm3.weight'
      # - 'backbone.norm3.bias'
      # - 'cls_head.fc_cls.weight'
#     arch: 
#       embed_dims: 96
#       num_layers: 16
#       num_heads: 1
#       downscale_indices: [1, 3, 14]

criterions:
- target: torch.nn.CrossEntropyLoss
  # params:
  #   label_smoothing: 0.1
  weight: 1.0
  name: ce

# criterions:
# - target: denk_baseline.losses.DistillationLoss
#   params:
#     config:
#       criterion:
#         target: torch.nn.CrossEntropyLoss
#       teacher_model: 
#         target: projects.aij_2023.models.mvit.model.MViTModel
#         params:
#           num_classes: 1001
#           pretrained: ./mvit32.2_small_state_dict.pt  
#       distillation_type: hard
#       alpha: 0.5
#       tau: 1.0
#   weight: 1.0
#   name: distilation

optimizers:
- target: torch.optim.AdamW
  params:
    lr: 0.0001
    weight_decay: 0.05
  scheduler:
    target: pl_bolts.optimizers.lr_scheduler.LinearWarmupCosineAnnealingLR
    params:
      warmup_epochs: 2
      max_epochs: 128
      warmup_start_lr: 0.00005
      eta_min: 0.00001
    additional:
      monitor: f1score_valid
    
metrics:
- target: torchmetrics.Precision
  name: precision
  params:
    num_classes: 1001
    task: multiclass
    average: macro
- target: torchmetrics.Recall
  name: recall
  params:
    num_classes: 1001
    task: multiclass
    average: macro
- target: torchmetrics.F1Score
  name: f1score
  params:
    num_classes: 1001
    task: multiclass
    average: macro
- target: denk_baseline.metrics.MeanAccuracyScore
  name: mascore

callbacks:
- target: pytorch_lightning.callbacks.LearningRateMonitor
- target: pytorch_lightning.callbacks.ModelCheckpoint
  params:
    filename: best_f1score-{epoch:03d}-{f1score_valid:3.3f}-{precision_valid:3.3f}-{recall_valid:3.3f}-{total_loss_valid:3.3f}
    monitor: f1score_valid
    mode: max
    save_top_k: 3
    save_last: false
    save_weights_only: false

datasets:
  train:
    target: projects.aij_2023.dataset.TrainVideoDataset
    params:
      csv_path: projects/aij_2023/data/train_15.csv
      json_path: projects/aij_2023/data/classes.json
      video_folder: /home/user/datasets/slovo/video
      min_side: 256
      sample_size: 224 
      sample_stride: 2 
      sample_n_frames: 32
      start_delta: 4
      use_dwt: true
  valid:
    target: projects.aij_2023.dataset.ValidVideoDataset
    params:
      csv_path: projects/aij_2023/data/test_15.csv
      json_path: projects/aij_2023/data/classes.json
      video_folder: /home/user/datasets/slovo/video
      min_side: 256
      sample_size: 224 
      sample_stride: 2 
      sample_n_frames: 32
      use_dwt: true

dataloaders:
  train:
    target: torch.utils.data.DataLoader
    params:
      shuffle: false
      batch_size: 32
      num_workers: 16
      drop_last: false
      pin_memory: true
    sampler: 
      target: torch.utils.data.RandomSampler
  valid:
    target: torch.utils.data.DataLoader
    params:
      shuffle: false
      batch_size: 32
      num_workers: 16
      drop_last: false
      pin_memory: true
    sampler: 
      target: torch.utils.data.SequentialSampler
